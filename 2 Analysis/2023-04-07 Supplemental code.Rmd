---
title: "Untitled"
author: "Dan Aurell"
date: "2023-04-07"
output:   
  html_document: 
    keep_md: yes
---

# Check whether colonies with missing data are used

Check whether lmer/glmer uses observations that have missing data
2023-04-07

Result:
- If I have two observations, but not a third one, lmer uses the observations I have
- This makes it important to report the sample size per date since it may vary

```{r}
# Take datum from Data Preparation pipeline

datum %>%
  filter(days %in% c(0, 21, 42)) %>% 
  group_by(days) %>% 
  summarize(n = n()) %>% 
  arrange(desc(n))
# 47, 47, 42; there are already 5 observations missing on Day 42

# Remove some extra
remove <- c("D20", "D15", "C15", "9", "RC1", "L75", "D22", "C12", "D26", "C2")

testdata1 <- datum %>%
  filter(days %in% c(0, 21, 42),
         (!(col_no %in% remove) | days != "42"))

testdata1 %>% 
  group_by(days) %>% 
  summarize(n = n()) %>% 
  arrange(desc(n))
# 47, 47, 33
# 14 colonies missing on Day 42

sampletimes <- testdata1 %>% 
  group_by(col_no) %>% 
  summarize(n = n()) %>% 
  arrange(desc(n))

# the 14 colonies missing on Day 42
missing <- sampletimes$col_no[sampletimes$n == 2]

testdata2 <- datum %>%
  filter(days %in% c(0, 21, 42),
         (!(col_no %in% missing))
         )

testdata2 %>% 
  group_by(days) %>% 
  summarize(n = n()) %>% 
  arrange(desc(n))
# 33, 33, 33
# 14 colonies missing on Day 42



m.bee1 <- lmer(bees_frames ~ trt + days + trt:days + (1 | col_no), data = testdata1)

m.bee2 <- lmer(bees_frames ~ trt + days + trt:days + (1 | col_no), data = testdata2)

summary(m.bee1)
summary(m.bee2)
```


# Learning how to include an offset in models to represent a denominator 
(e.g., in the models for )

```{r}
if(FALSE){

# Make tempdatum

tempdatum <- datum %>% 
  filter(days %in% c(0,21,42),
         !(col_no %in% qless)
  )


# a priori model
m.phor <- glmer.nb(mites_recov_total ~ 
                         trt + 
                         days + 
                         trt:days + 
                         (1 | col_no), 
                       data = tempdatum)
summary(m.phor)

# m2021S <- glm(cbind(SummerLost,SummerAlive)~OperationType, family=quasibinomial, data = AnDat2021S)
# Note, quasi families cannot be used in glmer()


# Make 
str(datum)
datum$mites_recov_total <- as.numeric(datum$mites_recov_total)

# Trying to take into account the number of bees per sample


m.phor <- glmer.nb(cbind(mites_recov_total, bees_without_mites) ~ 
                     trt + 
                     days + 
                     trt:days + 
                     (1 | col_no), 
                   data = tempdatum)
summary(m.phor)




m.phor.off <- glmer.nb(mites_recov_total ~ 
                     trt + 
                     days + 
                     trt:days + 
                    offset(log(est_bee_num_by_wt_floor)) +
                     (1 | col_no),
                   data = tempdatum)
summary(m.phor.off) # Very different coefficients...
}
```

## Other examples

https://stats.stackexchange.com/questions/88960/lme4-glmer-problems-with-offset

https://rpubs.com/bbolker/glmer_offset

mod.glmer1 <- glmer(cbind(marked,unmarked) ~ 
                      area + (1 | site) + 
                      offset(sampl_effort), 
                    family=binomial, data=testdatum)

mod.glmer1 <- glmer(cbind(marked,unmarked) ~ 
                    area + 
                    (1 | site) + 
                    offset(sampl_effort), 
                  family=binomial, 
                  data=testdatum)

mod.glmer1 <- glmer.nb(marked ~ 
                      area + 
                      (1 | site) +
                    offset(logit(total)),
                    data=testdatum)

mod.glmer1 <- glmer.nb(marked ~ 
                         area + 
                         (1 | site) +
                         offset(logit(sampl_effort)),
                       data=testdatum)

summary(mod.glmer1)


## I've figured it out


```{r}
# Vector of queen events
qless <- c("D8", "RC1", "D21", "D24", "C6", "BC15")
datum <- read.csv("../2 Analysis/data_prepped/datum_prepped.csv")
datum$trt <- factor(datum$trt , levels=c("Apivar", "Apiguard_Api", "AEC"))
datum$days <- factor(datum$days)

tempdatum <- datum %>% 
  filter(days %in% c(0,21,42),
         !(col_no %in% qless)
         )

m.phor <- glmer.nb(mites_recov_total ~ 
                     trt + 
                     days + 
                     trt:days + 
                     offset(log(est_bee_num_by_wt_floor)) +
                     (1 | col_no),
                   data = tempdatum)
summary(m.phor)
```


## Understand proportional increases and decreases

# Dynamics of Varroa Infestation in Colonies Treated with Amitraz E.C.

```{r}
emmeans(m.phor, pairwise ~ days | trt, type = "response")$contrasts

1/32.4498
1/0.0844


confint(emmeans(m.phor, pairwise ~ days | trt, type = "response"))$contrasts

# 0-21 95% CI
1/71.142
1/14.8011

# 21-42 95% CI
1/0.185
1/0.0385

```



## How to interpret the output of models

```{r}
# What's the mean of the offset? 
mean(tempdatum$est_bee_num_by_wt_floor) 
# 321.3
# To express model estimates as number of Varroa per 100 bees, take
  # yvar*100/321.3
```

# Workflow to figure out how to model and interpret proportion of Varroa in worker brood cells

```{r}
# Vector of queen events
qless <- c("D8", "RC1", "D21", "D24", "C6", "BC15")
datum <- read.csv("../2 Analysis/data_prepped/datum_prepped.csv")
datum$trt <- factor(datum$trt , levels=c("Apivar", "Apiguard_Api", "AEC"))
datum$days <- factor(datum$days)

tempdatum <- datum %>% 
  filter(days %in% c(0,21,42),
         !(col_no %in% qless)
         ) %>%
  mutate(tot = wk_cells_infested_estimate + phoretic_mites_num_estimate,
           perc_of_mitepop_wkbrd = 100*wk_cells_infested_estimate/tot
           )
```


Run models
```{r}
# This is a first try at analyzing the proportion of mites that are in the reproductive phase. I know it is not technically correct, since it assumes an unbounded distribution but in this case it is bounded by 0 and 100.

# Also, the model fit for the null model is singular

m.perc_mitepop_wkbrd <- lmer(perc_of_mitepop_wkbrd ~ 
                   trt + 
                   days + 
                   trt:days + 
                  (1 | col_no), 
                 data = tempdatum)
summary(m.perc_mitepop_wkbrd)

emmip(m.perc_mitepop_wkbrd, trt~days, type = "response", CIs = TRUE)

m.perc_mitepop_wkbrd.ML <- lmer(perc_of_mitepop_wkbrd ~ 
                   trt + 
                   days + 
                   trt:days + 
                  (1 | col_no), 
                 data = tempdatum, REML = FALSE)

m.perc_mitepop_wkbrd.0.ML <- lmer(perc_of_mitepop_wkbrd ~ 
                   trt + 
                   days + 
                   # trt:days + 
                  (1 | col_no), 
                 data = tempdatum, REML = FALSE) # The model fit is singular
summary(m.perc_mitepop_wkbrd.0.ML)

anova(m.perc_mitepop_wkbrd.ML, m.perc_mitepop_wkbrd.0.ML)
# The more complex model is preferred

summary(m.perc_mitepop_wkbrd)

```


Model interpretation
```{r}
# For the incorrect percentage model
emplot_percent <- emmip(m.perc_mitepop_wkbrd, trt~days, type = "response", CIs = TRUE, plotit = FALSE)
emplot_percent$days <- as.numeric(as.character(emplot_percent$days))
emplot_percent$trt <- factor(emplot_percent$trt, levels = c("Apivar", "AEC", "Apiguard_Api"))

# For the superior proportion model

mean(tempdatum$tot, na.rm = T) 
# 1803.982 is the mean number of total varroa per colony
# As I understand it, the predictions are a mean number of varroa in brood cells per colony
# To transform this value to the percent of varroa in worker brood cells I think I am supposed to...
# percent varroa in worker brood cells = response*100/1803.982

emplot_prop_wrong <- emmip(m.prop, trt~days, type = "response", CIs = TRUE, plotit = FALSE)
# append _t to all the transformed estimates and CIs
emplot_prop_wrong <- emplot_prop_wrong %>% 
  mutate(yvar_t = yvar*100/1803.982,
         LCL_t = LCL*100/1803.982,
         UCL_t = UCL*100/1803.982
         )
# This method does not provide estimates that align with arithmetic means


# Understanding these predictions in emplot_prop

#### Troubleshooting possible sources of error

# 1. NAs in tempdatum messing me up?
tempdatum %>% select(col_no, days, wk_cells_infested_estimate, phoretic_mites_num_estimate, tot, perc_of_mitepop_wkbrd)
# I Don't have excessive NAs

# 2. Maybe I misunderstood and I should not be running the offset on the log scale
# I looked at the m.prop model object and confirmed it was specified using the link = log


# Raw predictions day 0: 
# Apivar 737
# Apiguard: 721
# AEC: 761
# WHAT DO THESE PREDICTIONS MEAN????
    # The number of reproductive Varroa in a colony?
# 731/1803 is 40 percent


tempdatum %>% filter(days == 0) %>% summarise(wk = mean(wk_cells_infested_estimate), phor = mean(phoretic_mites_num_estimate), ttl = mean(tot), perc = mean(perc_of_mitepop_wkbrd))


## I found a solution after googling "how to interpret emmeans with offset"
# emmeans documentation: https://cran.r-project.org/web/packages/emmeans/vignettes/sophisticated.html#offsets


emplot_prop <- emmip(m.prop, trt~days, type = "response", CIs = TRUE, plotit = FALSE, offset = log(100))
# Aside from following a documented method (as mentioned above), this passes a reality check:
#   This method does provide estimates that are in line with my initial gaussian model of percentages; 
#   it also provides estimates that are in line with the arithmetic means at each day

emplot_prop$days <- as.numeric(as.character(emplot_prop$days))
emplot_prop$trt <- factor(emplot_prop$trt, levels = c("Apivar", "AEC", "Apiguard_Api"))
levels(emplot_prop$trt) # check order of factors
```


# What is emmeans joint_tests doing?

According to https://cran.r-project.org/web/packages/emmeans/vignettes/interactions.html
- it obtains and tests the interaction contrasts for all effects in the model

What is an interaction contrast?
- An interaction contrast is a contrast of contrasts.

```{r}
noise.lm <- lm(noise/10 ~ size * type * side, data = auto.noise)
anova(noise.lm)

emmip(noise.lm, type~size | side)

# For medium-sized cars, standard mufflers are louder than octel mufflers
```


## Interaction contrasts

```{r}
emm_s.t <- emmeans(noise.lm, pairwise ~ size | type)
emm_s.t # This collapses the data for both sides together

emmeans(m.bee.f, pairwise ~ trt | days, type = "response")

emm_t.d <- emmeans(m.bee.f, pairwise ~ trt | days)
emm_t.d

IC_st <- contrast(emm_s.t[[1]], interaction = c("poly", "consec"), by = NULL)
IC_st

IC_td <- contrast(emm_t.d[[1]], interaction = "consec")
IC_td

IC_td <- contrast(emm_t.d[[1]], interaction = TRUE)
IC_td

IC_td <- contrast(emm_t.d[[1]], interaction = TRUE, by = NULL)
IC_td

```

```{r}
contrast(emm_s.t[[1]], "poly")   ## 'by = "type"' already in previous result
```
## To compare these contrasts     
```{r}
IC_st <- contrast(emm_s.t[[1]], interaction = c("poly", "consec"), by = NULL)
IC_st

# The difference between Octel and Standard is significant within the quadratic, but not within linear
```



```{r}
joint_tests(noise.lm)
```
## Work through joint_tests example

```{r}
View(pigs)
pigs.lm <- lm(log(conc) ~ source * factor(percent), data = pigs)

(jt <- joint_tests(pigs.lm))             ## will be same as type III ANOVA

### Estimable functions associated with "percent"
attr(jt, "est.fcns") $ "percent"

joint_tests(pigs.lm, weights = "outer")  ## differently weighted

joint_tests(pigs.lm, by = "source")      ## separate joint tests of 'percent'

### Comparisons with type III tests in SAS
toy = data.frame(
    treat = rep(c("A", "B"), c(4, 6)),
    female = c(1, 0, 0, 1,   0, 0, 0, 1, 1, 0 ),
    resp = c(17, 12, 14, 19, 28, 26, 26, 34, 33, 27))
toy.fac = lm(resp ~ treat * factor(female), data = toy)
toy.cov = lm(resp ~ treat * female, data = toy)
# (These two models have identical fitted values and residuals)

# -- SAS output we'd get with toy.fac --
## Source          DF    Type III SS    Mean Square   F Value   Pr > F
## treat            1    488.8928571    488.8928571    404.60   <.0001
## female           1     78.8928571     78.8928571     65.29   0.0002
## treat*female     1      1.7500000      1.7500000      1.45   0.2741
# 
# -- SAS output we'd get with toy.cov --
## Source          DF    Type III SS    Mean Square   F Value   Pr > F
## treat            1    252.0833333    252.0833333    208.62   <.0001
## female           1     78.8928571     78.8928571     65.29   0.0002
## female*treat     1      1.7500000      1.7500000      1.45   0.2741

joint_tests(toy.fac)
joint_tests(toy.cov)   # female is regarded as a 2-level factor by default

## Treat 'female' as a numeric covariate (via cov.keep = 0)
## ... then tests depend on where we center things

# Center around the mean
joint_tests(toy.cov, cov.keep = 0, cov.reduce = meanint)
# Center around zero (like SAS's results for toy.cov)
joint_tests(toy.cov, cov.keep = 0, cov.reduce = symmint(0))
# Center around 0.5 (like SAS's results for toy.fac)
joint_tests(toy.cov, cov.keep = 0, cov.reduce = range)

### Example with empty cells and confounded effects
low3 <- unlist(attr(ubds, "cells")[1:3]) 
ubds.lm <- lm(y ~ A*B*C, data = ubds, subset = -low3)

# Show overall joint tests by C:
ref_grid(ubds.lm, by = "C") |> contrast("consec") |> test(joint = TRUE)

# Break each of the above into smaller components:
joint_tests(ubds.lm, by = "C")
```


